{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNl/Xh65LnP37e895VexM1V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EggPudding/Deep-Learning-Paper-with-Codes/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRfBzNVtGO_"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsA1wMFB5ZRs"
      },
      "source": [
        "### AlexNet 모델의 정의 및 초기화\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBVT_mDu5WxC"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "import torchsummary\r\n",
        "\r\n",
        "class AlexNet(nn.Module):\r\n",
        "  \"\"\" AlexNet Implementation\r\n",
        "  Original Paper: https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\r\n",
        "\r\n",
        "  원 논문에서 사용하는 GPU Paralell은 사용하지 않았습니다.\r\n",
        "  추가로 MNIST를 대상으로 하므로 모델의 구조를 간단히 수정하였습니다.\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, num_classes=10):\r\n",
        "    super(AlexNet, self).__init__()\r\n",
        "\r\n",
        "    self.feature_extract = nn.Sequential(\r\n",
        "      nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\r\n",
        "      nn.ReLU(inplace=True),     \r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),  \r\n",
        "    )\r\n",
        "\r\n",
        "\r\n",
        "    self.classifier = nn.Sequential(\r\n",
        "      nn.Dropout(),\r\n",
        "      nn.Linear(256 * 2 * 2, 512),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.Dropout(),\r\n",
        "      nn.Linear(512, num_classes),       \r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.feature_extract(x)\r\n",
        "    x = torch.flatten(x, 1)\r\n",
        "    x = self.classifier(x)\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXTxJ_v78Urp"
      },
      "source": [
        "### 학습 환경 설명 및 학습(Train) 함수 정의\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vb-7Ow98M-f"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "\r\n",
        "model = AlexNet()\r\n",
        "model.to(device)\r\n",
        "model = torch.nn.DataParallel(model)\r\n",
        "\r\n",
        "cudnn.benchmark = True\r\n",
        "\r\n",
        "learning_rate = 0.01\r\n",
        "batch_size = 128\r\n",
        "max_epoch = 10\r\n",
        "\r\n",
        "model_path = 'alexnet_mnist.pt'\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCKN2xvOuRkK",
        "outputId": "6bf3bc30-9e46-4771-e30b-dd5a95f791ae"
      },
      "source": [
        "torchsummary.summary(model, (1, 28, 28))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 28, 28]             640\n",
            "              ReLU-2           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-3           [-1, 64, 13, 13]               0\n",
            "            Conv2d-4          [-1, 128, 13, 13]          73,856\n",
            "              ReLU-5          [-1, 128, 13, 13]               0\n",
            "         MaxPool2d-6            [-1, 128, 6, 6]               0\n",
            "            Conv2d-7            [-1, 256, 6, 6]         295,168\n",
            "              ReLU-8            [-1, 256, 6, 6]               0\n",
            "         MaxPool2d-9            [-1, 256, 2, 2]               0\n",
            "          Dropout-10                 [-1, 1024]               0\n",
            "           Linear-11                  [-1, 512]         524,800\n",
            "             ReLU-12                  [-1, 512]               0\n",
            "          Dropout-13                  [-1, 512]               0\n",
            "           Linear-14                   [-1, 10]           5,130\n",
            "          AlexNet-15                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 899,594\n",
            "Trainable params: 899,594\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.38\n",
            "Params size (MB): 3.43\n",
            "Estimated Total Size (MB): 4.82\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrIv6Ao8u0cG"
      },
      "source": [
        "### 학습 (Train) & 검증 (Validation) 함수 정의\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfOWR0PXu0nv"
      },
      "source": [
        "def train(epoch, max_epoch):\r\n",
        "  print(f\"Train Epoch [{epoch}/{max_epoch}]\")\r\n",
        "  model.train()\r\n",
        "\r\n",
        "  train_loss = 0\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  acc = 0\r\n",
        "\r\n",
        "  for idx, (x, y) in enumerate(train_dataloader):\r\n",
        "    x = x.to(device)\r\n",
        "    y = y.to(device)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "\r\n",
        "    y_pred = model(x)\r\n",
        "    loss = criterion(y_pred, y)\r\n",
        "\r\n",
        "    loss.backward()\r\n",
        "\r\n",
        "    optimizer.step()\r\n",
        "    train_loss += loss.item()\r\n",
        "    _, inference = y_pred.max(1)\r\n",
        "\r\n",
        "    total += x.size(0)\r\n",
        "    correct += inference.eq(y).sum().item()\r\n",
        "\r\n",
        "    if idx % 100 == 0:\r\n",
        "      print(f\"Epoch [{epoch}/{max_epoch}] Batch [{idx}] Train Loss: {loss.item()}\")\r\n",
        "\r\n",
        "  acc = 100*correct/total\r\n",
        "  print(f\"Epoch [{epoch}/{max_epoch}] Train Loss: {train_loss/total} Train Accuracy: {acc}\")\r\n",
        "\r\n",
        "def valid(epoch, max_epoch):\r\n",
        "  print(f\"Valid Epoch [{epoch}/{max_epoch}]\")\r\n",
        "  model.eval()\r\n",
        "  \r\n",
        "  valid_loss = 0\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "\r\n",
        "  for idx, (x, y) in enumerate(valid_dataloader):\r\n",
        "    x = x.to(device)\r\n",
        "    y = y.to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      y_pred = model(x)\r\n",
        "      valid_loss += criterion(y_pred, y).item()\r\n",
        "\r\n",
        "      _, inference = y_pred.max(1)\r\n",
        "\r\n",
        "      total += x.size(0)\r\n",
        "      correct += inference.eq(y).sum().item()\r\n",
        "\r\n",
        "  acc = 100*correct/total\r\n",
        "  print(f\"Epoch [{epoch}/{max_epoch}] Valid Loss: {valid_loss/total} Valid Accuracy: {acc}\")\r\n",
        "\r\n",
        "  if not os.path.exists('checkpoint'):\r\n",
        "    os.mkdir('checkpoint')\r\n",
        "  \r\n",
        "  torch.save(model.state_dict(), f'checkpoint/{model_path}')\r\n",
        "  print(f\"Epoch [{epoch}/{max_epoch}] Valid Model Saved: checkpoint/{model_path}\")\r\n",
        "\r\n",
        "def lr_schedule(optimizer, epoch):\r\n",
        "  if epoch == 5:\r\n",
        "    lr = learning_rate / 10\r\n",
        "    for param_group in optimizer.param_groups:\r\n",
        "      param_group['lr'] = lr\r\n",
        "  "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVm4R54G8Eln"
      },
      "source": [
        "### MNIST 데이터셋 다운로드 및 불러오기\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63UmRiK8DyE"
      },
      "source": [
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\r\n",
        "valid_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\r\n",
        "\r\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\r\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lftyz6uG-P1T"
      },
      "source": [
        "### 학습 (Train) 진행\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UhztDOx-Oa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bcef8f-16a9-435f-ab2f-96c8cc03759c"
      },
      "source": [
        "for epoch in range(0, max_epoch):\r\n",
        "  lr_schedule(optimizer, epoch)\r\n",
        "  train(epoch, max_epoch)\r\n",
        "  valid(epoch, max_epoch)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch [0/10]\n",
            "Epoch [0/10] Batch [0] Train Loss: 0.2873525619506836\n",
            "Epoch [0/10] Batch [100] Train Loss: 0.21464131772518158\n",
            "Epoch [0/10] Batch [200] Train Loss: 0.15093854069709778\n",
            "Epoch [0/10] Batch [300] Train Loss: 0.17556892335414886\n",
            "Epoch [0/10] Batch [400] Train Loss: 0.2250879406929016\n",
            "Epoch [0/10] Train Loss: 0.0018991753535345197 Train Accuracy: 93.645\n",
            "Valid Epoch [0/10]\n",
            "Epoch [0/10] Valid Loss: 0.0009041530852671712 Valid Accuracy: 96.83\n",
            "Epoch [0/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [1/10]\n",
            "Epoch [1/10] Batch [0] Train Loss: 0.1981702744960785\n",
            "Epoch [1/10] Batch [100] Train Loss: 0.29971346259117126\n",
            "Epoch [1/10] Batch [200] Train Loss: 0.24769625067710876\n",
            "Epoch [1/10] Batch [300] Train Loss: 0.26893478631973267\n",
            "Epoch [1/10] Batch [400] Train Loss: 0.13225844502449036\n",
            "Epoch [1/10] Train Loss: 0.001721328614745289 Train Accuracy: 94.10166666666667\n",
            "Valid Epoch [1/10]\n",
            "Epoch [1/10] Valid Loss: 0.0008588661203742958 Valid Accuracy: 96.91\n",
            "Epoch [1/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [2/10]\n",
            "Epoch [2/10] Batch [0] Train Loss: 0.5776817798614502\n",
            "Epoch [2/10] Batch [100] Train Loss: 0.2813897728919983\n",
            "Epoch [2/10] Batch [200] Train Loss: 0.22049927711486816\n",
            "Epoch [2/10] Batch [300] Train Loss: 0.17086362838745117\n",
            "Epoch [2/10] Batch [400] Train Loss: 0.5044317245483398\n",
            "Epoch [2/10] Train Loss: 0.0018603665607670942 Train Accuracy: 93.78166666666667\n",
            "Valid Epoch [2/10]\n",
            "Epoch [2/10] Valid Loss: 0.0007988434102619067 Valid Accuracy: 97.14\n",
            "Epoch [2/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [3/10]\n",
            "Epoch [3/10] Batch [0] Train Loss: 0.13292257487773895\n",
            "Epoch [3/10] Batch [100] Train Loss: 0.4928439259529114\n",
            "Epoch [3/10] Batch [200] Train Loss: 0.11331220716238022\n",
            "Epoch [3/10] Batch [300] Train Loss: 0.3017105162143707\n",
            "Epoch [3/10] Batch [400] Train Loss: 0.1538447141647339\n",
            "Epoch [3/10] Train Loss: 0.001801917666879793 Train Accuracy: 93.895\n",
            "Valid Epoch [3/10]\n",
            "Epoch [3/10] Valid Loss: 0.0011721757435472682 Valid Accuracy: 96.25\n",
            "Epoch [3/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [4/10]\n",
            "Epoch [4/10] Batch [0] Train Loss: 0.23442761600017548\n",
            "Epoch [4/10] Batch [100] Train Loss: 0.27658817172050476\n",
            "Epoch [4/10] Batch [200] Train Loss: 0.14863960444927216\n",
            "Epoch [4/10] Batch [300] Train Loss: 0.1306043118238449\n",
            "Epoch [4/10] Batch [400] Train Loss: 0.24529877305030823\n",
            "Epoch [4/10] Train Loss: 0.001688263237507393 Train Accuracy: 94.24666666666667\n",
            "Valid Epoch [4/10]\n",
            "Epoch [4/10] Valid Loss: 0.000975789039535448 Valid Accuracy: 96.58\n",
            "Epoch [4/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [5/10]\n",
            "Epoch [5/10] Batch [0] Train Loss: 0.3182876706123352\n",
            "Epoch [5/10] Batch [100] Train Loss: 0.11698917299509048\n",
            "Epoch [5/10] Batch [200] Train Loss: 0.18694384396076202\n",
            "Epoch [5/10] Batch [300] Train Loss: 0.12906835973262787\n",
            "Epoch [5/10] Batch [400] Train Loss: 0.06671686470508575\n",
            "Epoch [5/10] Train Loss: 0.0012292425476014613 Train Accuracy: 95.72166666666666\n",
            "Valid Epoch [5/10]\n",
            "Epoch [5/10] Valid Loss: 0.000605014722191845 Valid Accuracy: 97.73\n",
            "Epoch [5/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [6/10]\n",
            "Epoch [6/10] Batch [0] Train Loss: 0.06974172592163086\n",
            "Epoch [6/10] Batch [100] Train Loss: 0.07951215654611588\n",
            "Epoch [6/10] Batch [200] Train Loss: 0.17662274837493896\n",
            "Epoch [6/10] Batch [300] Train Loss: 0.17622409760951996\n",
            "Epoch [6/10] Batch [400] Train Loss: 0.16742652654647827\n",
            "Epoch [6/10] Train Loss: 0.0010471027948583166 Train Accuracy: 96.35333333333334\n",
            "Valid Epoch [6/10]\n",
            "Epoch [6/10] Valid Loss: 0.0005497478109260555 Valid Accuracy: 97.93\n",
            "Epoch [6/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [7/10]\n",
            "Epoch [7/10] Batch [0] Train Loss: 0.15407153964042664\n",
            "Epoch [7/10] Batch [100] Train Loss: 0.1534481793642044\n",
            "Epoch [7/10] Batch [200] Train Loss: 0.14095519483089447\n",
            "Epoch [7/10] Batch [300] Train Loss: 0.14110812544822693\n",
            "Epoch [7/10] Batch [400] Train Loss: 0.05409485846757889\n",
            "Epoch [7/10] Train Loss: 0.0009796308390097692 Train Accuracy: 96.48833333333333\n",
            "Valid Epoch [7/10]\n",
            "Epoch [7/10] Valid Loss: 0.0005527223100041738 Valid Accuracy: 97.88\n",
            "Epoch [7/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [8/10]\n",
            "Epoch [8/10] Batch [0] Train Loss: 0.16235677897930145\n",
            "Epoch [8/10] Batch [100] Train Loss: 0.14018873870372772\n",
            "Epoch [8/10] Batch [200] Train Loss: 0.08640256524085999\n",
            "Epoch [8/10] Batch [300] Train Loss: 0.06465177983045578\n",
            "Epoch [8/10] Batch [400] Train Loss: 0.07175654917955399\n",
            "Epoch [8/10] Train Loss: 0.0009185536579539379 Train Accuracy: 96.68833333333333\n",
            "Valid Epoch [8/10]\n",
            "Epoch [8/10] Valid Loss: 0.0005317673430370632 Valid Accuracy: 98.04\n",
            "Epoch [8/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [9/10]\n",
            "Epoch [9/10] Batch [0] Train Loss: 0.028667757287621498\n",
            "Epoch [9/10] Batch [100] Train Loss: 0.0691811814904213\n",
            "Epoch [9/10] Batch [200] Train Loss: 0.12893958389759064\n",
            "Epoch [9/10] Batch [300] Train Loss: 0.06432650238275528\n",
            "Epoch [9/10] Batch [400] Train Loss: 0.11642962694168091\n",
            "Epoch [9/10] Train Loss: 0.0008780209998910626 Train Accuracy: 96.78833333333333\n",
            "Valid Epoch [9/10]\n",
            "Epoch [9/10] Valid Loss: 0.0005013554554287111 Valid Accuracy: 98.06\n",
            "Epoch [9/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}