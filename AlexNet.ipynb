{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsos1Yio11CEDQ5DdTAzMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EggPudding/Deep-Learning-Practice-with-Codes/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKZqS8pvGk3w"
      },
      "source": [
        "## **ImageNet Classification with Deep Convolutional Neural Networks (NIPS 2012) Tutorial**\r\n",
        "\r\n",
        "*   Pratice for AlexNet Architecture\r\n",
        "*   Orginal Paper: https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\r\n",
        "*   Note that you first change **Runtime** to **GPU** setting\r\n",
        "*   **MNIST** Dataset is used for practice for simplicity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSZ7uTuWG_L4",
        "outputId": "aeb6307c-06b1-4b36-ac6d-ba386fdcc0e8"
      },
      "source": [
        "!nvidia-smi # Make Sure you are using GPU"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jan 25 02:04:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    32W /  70W |   1281MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsA1wMFB5ZRs"
      },
      "source": [
        "### **AlexNet Model Definition**\r\n",
        "* In this **Tutorial**, Model object for **MNIST** Dataset. So Original model architecture doesn't fit into size of **28x28** which is MNIST DIGIT Image\r\n",
        "* **MNIST** is dataset for classifying digit image into category from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBVT_mDu5WxC"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "# AlexNet Implementation\r\n",
        "# Model architecture adjusted to MNIST Dataset, so it is different from original one\r\n",
        "# Also GPU Parallel, LRN (Local Response Normalization) aren't utilized since they\r\n",
        "# are not used in recent researches as well as for reader's understanding.\r\n",
        "class AlexNet(nn.Module):\r\n",
        "  def __init__(self, num_classes=10):\r\n",
        "    super(AlexNet, self).__init__()\r\n",
        "\r\n",
        "    self.feature_extract = nn.Sequential(\r\n",
        "      nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "      nn.Conv2d(64, 128, kernel_size=3, padding=1),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),\r\n",
        "      nn.Conv2d(128, 256, kernel_size=3, padding=1),\r\n",
        "      nn.ReLU(inplace=True),     \r\n",
        "      nn.MaxPool2d(kernel_size=3, stride=2),  \r\n",
        "    )\r\n",
        "\r\n",
        "    self.classifier = nn.Sequential(\r\n",
        "      nn.Dropout(),\r\n",
        "      nn.Linear(256 * 2 * 2, 512),\r\n",
        "      nn.ReLU(inplace=True),\r\n",
        "      nn.Dropout(),\r\n",
        "      nn.Linear(512, num_classes),       \r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.feature_extract(x)\r\n",
        "    x = torch.flatten(x, 1)\r\n",
        "    x = self.classifier(x)\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXTxJ_v78Urp"
      },
      "source": [
        "### **Hyper Parameter Setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vb-7Ow98M-f"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # whether using gpu or cpu\r\n",
        "\r\n",
        "model = AlexNet() # model assignment\r\n",
        "model.to(device) # mapping model weight & bias into gpu memory\r\n",
        "model = torch.nn.DataParallel(model) # used for parallel setting\r\n",
        "\r\n",
        "cudnn.benchmark = True # using cudnn which optimizes the algorithm\r\n",
        "\r\n",
        "learning_rate = 0.01\r\n",
        "batch_size = 128\r\n",
        "max_epoch = 10\r\n",
        "\r\n",
        "model_path = 'alexnet_mnist.pt'\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss() # simple cross-entropy is utilized\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Adam optimizer utilized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SzYzTSlJdTm"
      },
      "source": [
        "* **torchsummary** is package for visualizing pytorch model.\r\n",
        "* Layers, Number of parameters can be viewed through this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCKN2xvOuRkK",
        "outputId": "7d69909e-dcad-4b29-a8f1-79eef0d03b1d"
      },
      "source": [
        "import torchsummary\r\n",
        "\r\n",
        "torchsummary.summary(model, (1, 28, 28)) # MNIST Image has 28 x 28 x 1 shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 28, 28]             640\n",
            "              ReLU-2           [-1, 64, 28, 28]               0\n",
            "         MaxPool2d-3           [-1, 64, 13, 13]               0\n",
            "            Conv2d-4          [-1, 128, 13, 13]          73,856\n",
            "              ReLU-5          [-1, 128, 13, 13]               0\n",
            "         MaxPool2d-6            [-1, 128, 6, 6]               0\n",
            "            Conv2d-7            [-1, 256, 6, 6]         295,168\n",
            "              ReLU-8            [-1, 256, 6, 6]               0\n",
            "         MaxPool2d-9            [-1, 256, 2, 2]               0\n",
            "          Dropout-10                 [-1, 1024]               0\n",
            "           Linear-11                  [-1, 512]         524,800\n",
            "             ReLU-12                  [-1, 512]               0\n",
            "          Dropout-13                  [-1, 512]               0\n",
            "           Linear-14                   [-1, 10]           5,130\n",
            "          AlexNet-15                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 899,594\n",
            "Trainable params: 899,594\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.38\n",
            "Params size (MB): 3.43\n",
            "Estimated Total Size (MB): 4.82\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrIv6Ao8u0cG"
      },
      "source": [
        "### **Training and Evaluation function definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfOWR0PXu0nv"
      },
      "source": [
        "def train(epoch, max_epoch):\r\n",
        "    print(f\"Train Epoch [{epoch}/{max_epoch}]\")\r\n",
        "    model.train() # Model to train mode\r\n",
        "\r\n",
        "    train_loss = 0\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    acc = 0\r\n",
        "\r\n",
        "    for idx, (x, y) in enumerate(train_dataloader):\r\n",
        "        x = x.to(device) # maps data into GPU memory\r\n",
        "        y = y.to(device)\r\n",
        "\r\n",
        "        optimizer.zero_grad() # reset gradients in optimizer before calculating the loss\r\n",
        "\r\n",
        "        y_pred = model(x) # model inference\r\n",
        "        loss = criterion(y_pred, y) # calculating the loss\r\n",
        "\r\n",
        "        loss.backward() # back-propagation to get cumulative gradients\r\n",
        "\r\n",
        "        optimizer.step() # update model parameters\r\n",
        "        train_loss += loss.item()\r\n",
        "        _, inference = y_pred.max(1)\r\n",
        "\r\n",
        "        total += x.size(0)\r\n",
        "        correct += inference.eq(y).sum().item()\r\n",
        "\r\n",
        "        if idx % 100 == 0:\r\n",
        "            print(f\"Epoch [{epoch}/{max_epoch}] Batch [{idx}] Train Loss: {loss.item()}\")\r\n",
        "\r\n",
        "    acc = 100*correct/total\r\n",
        "    print(f\"Epoch [{epoch}/{max_epoch}] Train Loss: {train_loss/total} Train Accuracy: {acc}\")\r\n",
        "\r\n",
        "def valid(epoch, max_epoch):\r\n",
        "    print(f\"Valid Epoch [{epoch}/{max_epoch}]\")\r\n",
        "    model.eval() # Model to evaluation mode\r\n",
        "\r\n",
        "    valid_loss = 0\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "\r\n",
        "    for idx, (x, y) in enumerate(valid_dataloader):\r\n",
        "        x = x.to(device) # maps data into GPU memory\r\n",
        "        y = y.to(device)\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            y_pred = model(x) # model inference\r\n",
        "            valid_loss += criterion(y_pred, y).item()\r\n",
        "\r\n",
        "            _, inference = y_pred.max(1)\r\n",
        "\r\n",
        "            total += x.size(0)\r\n",
        "            correct += inference.eq(y).sum().item()\r\n",
        "\r\n",
        "    acc = 100*correct/total\r\n",
        "    print(f\"Epoch [{epoch}/{max_epoch}] Valid Loss: {valid_loss/total} Valid Accuracy: {acc}\")\r\n",
        "\r\n",
        "    if not os.path.exists('checkpoint'):\r\n",
        "        os.mkdir('checkpoint')\r\n",
        "\r\n",
        "    torch.save(model.state_dict(), f'checkpoint/{model_path}')\r\n",
        "    print(f\"Epoch [{epoch}/{max_epoch}] Valid Model Saved: checkpoint/{model_path}\")\r\n",
        "\r\n",
        "# Custom leraning rate scheduler is use.\r\n",
        "# Decay learning rate by 10 at epoch 5.\r\n",
        "def lr_schedule(optimizer, epoch):\r\n",
        "    if epoch == 5:\r\n",
        "        lr = learning_rate / 10\r\n",
        "        for param_group in optimizer.param_groups:\r\n",
        "            param_group['lr'] = lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVm4R54G8Eln"
      },
      "source": [
        "### **Data Preparation**\r\n",
        "* First we are going to use **torchvision** which contains famous vision dataset, and we will use **MNIST** especially \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63UmRiK8DyE"
      },
      "source": [
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "\r\n",
        "transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\r\n",
        "valid_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\r\n",
        "\r\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\r\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lftyz6uG-P1T"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UhztDOx-Oa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f18f6b-56d7-4962-d57d-205adc7f5fd7"
      },
      "source": [
        "for epoch in range(0, max_epoch):\r\n",
        "    lr_schedule(optimizer, epoch)\r\n",
        "    train(epoch, max_epoch)\r\n",
        "    valid(epoch, max_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch [0/10]\n",
            "Epoch [0/10] Batch [0] Train Loss: 2.3007636070251465\n",
            "Epoch [0/10] Batch [100] Train Loss: 0.9037967324256897\n",
            "Epoch [0/10] Batch [200] Train Loss: 0.6736580729484558\n",
            "Epoch [0/10] Batch [300] Train Loss: 0.37950873374938965\n",
            "Epoch [0/10] Batch [400] Train Loss: 0.43045854568481445\n",
            "Epoch [0/10] Train Loss: 0.006541210406025251 Train Accuracy: 72.435\n",
            "Valid Epoch [0/10]\n",
            "Epoch [0/10] Valid Loss: 0.0017999021627008915 Valid Accuracy: 93.22\n",
            "Epoch [0/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [1/10]\n",
            "Epoch [1/10] Batch [0] Train Loss: 0.6461343169212341\n",
            "Epoch [1/10] Batch [100] Train Loss: 0.324937641620636\n",
            "Epoch [1/10] Batch [200] Train Loss: 0.17657935619354248\n",
            "Epoch [1/10] Batch [300] Train Loss: 0.34770509600639343\n",
            "Epoch [1/10] Batch [400] Train Loss: 0.40423160791397095\n",
            "Epoch [1/10] Train Loss: 0.002769552831227581 Train Accuracy: 89.32\n",
            "Valid Epoch [1/10]\n",
            "Epoch [1/10] Valid Loss: 0.0014781719436869026 Valid Accuracy: 94.52\n",
            "Epoch [1/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [2/10]\n",
            "Epoch [2/10] Batch [0] Train Loss: 0.4429759383201599\n",
            "Epoch [2/10] Batch [100] Train Loss: 0.3818788230419159\n",
            "Epoch [2/10] Batch [200] Train Loss: 0.2887078523635864\n",
            "Epoch [2/10] Batch [300] Train Loss: 0.327263742685318\n",
            "Epoch [2/10] Batch [400] Train Loss: 0.2350756973028183\n",
            "Epoch [2/10] Train Loss: 0.002436638318623106 Train Accuracy: 90.805\n",
            "Valid Epoch [2/10]\n",
            "Epoch [2/10] Valid Loss: 0.001506925904378295 Valid Accuracy: 94.22\n",
            "Epoch [2/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [3/10]\n",
            "Epoch [3/10] Batch [0] Train Loss: 0.3711458742618561\n",
            "Epoch [3/10] Batch [100] Train Loss: 0.35127517580986023\n",
            "Epoch [3/10] Batch [200] Train Loss: 0.29277855157852173\n",
            "Epoch [3/10] Batch [300] Train Loss: 0.15441550314426422\n",
            "Epoch [3/10] Batch [400] Train Loss: 0.33454060554504395\n",
            "Epoch [3/10] Train Loss: 0.0023515004114558298 Train Accuracy: 91.39166666666667\n",
            "Valid Epoch [3/10]\n",
            "Epoch [3/10] Valid Loss: 0.0013118261102586985 Valid Accuracy: 95.16\n",
            "Epoch [3/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [4/10]\n",
            "Epoch [4/10] Batch [0] Train Loss: 0.21412287652492523\n",
            "Epoch [4/10] Batch [100] Train Loss: 0.18008467555046082\n",
            "Epoch [4/10] Batch [200] Train Loss: 0.3153802752494812\n",
            "Epoch [4/10] Batch [300] Train Loss: 0.30188509821891785\n",
            "Epoch [4/10] Batch [400] Train Loss: 0.35067495703697205\n",
            "Epoch [4/10] Train Loss: 0.0022988441362977027 Train Accuracy: 91.55166666666666\n",
            "Valid Epoch [4/10]\n",
            "Epoch [4/10] Valid Loss: 0.001169534586602822 Valid Accuracy: 95.84\n",
            "Epoch [4/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [5/10]\n",
            "Epoch [5/10] Batch [0] Train Loss: 0.2435954213142395\n",
            "Epoch [5/10] Batch [100] Train Loss: 0.15217304229736328\n",
            "Epoch [5/10] Batch [200] Train Loss: 0.09040122479200363\n",
            "Epoch [5/10] Batch [300] Train Loss: 0.22277353703975677\n",
            "Epoch [5/10] Batch [400] Train Loss: 0.2448822408914566\n",
            "Epoch [5/10] Train Loss: 0.0016125094635412098 Train Accuracy: 94.07333333333334\n",
            "Valid Epoch [5/10]\n",
            "Epoch [5/10] Valid Loss: 0.0007842486268375069 Valid Accuracy: 97.2\n",
            "Epoch [5/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [6/10]\n",
            "Epoch [6/10] Batch [0] Train Loss: 0.1128648892045021\n",
            "Epoch [6/10] Batch [100] Train Loss: 0.08679056167602539\n",
            "Epoch [6/10] Batch [200] Train Loss: 0.23168078064918518\n",
            "Epoch [6/10] Batch [300] Train Loss: 0.2117968201637268\n",
            "Epoch [6/10] Batch [400] Train Loss: 0.27180978655815125\n",
            "Epoch [6/10] Train Loss: 0.001388833698692421 Train Accuracy: 94.85666666666667\n",
            "Valid Epoch [6/10]\n",
            "Epoch [6/10] Valid Loss: 0.0007756116633769125 Valid Accuracy: 97.28\n",
            "Epoch [6/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [7/10]\n",
            "Epoch [7/10] Batch [0] Train Loss: 0.25017082691192627\n",
            "Epoch [7/10] Batch [100] Train Loss: 0.14613912999629974\n",
            "Epoch [7/10] Batch [200] Train Loss: 0.13259738683700562\n",
            "Epoch [7/10] Batch [300] Train Loss: 0.08335401117801666\n",
            "Epoch [7/10] Batch [400] Train Loss: 0.11867842823266983\n",
            "Epoch [7/10] Train Loss: 0.001279912685168286 Train Accuracy: 95.18666666666667\n",
            "Valid Epoch [7/10]\n",
            "Epoch [7/10] Valid Loss: 0.0007210988837294281 Valid Accuracy: 97.45\n",
            "Epoch [7/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [8/10]\n",
            "Epoch [8/10] Batch [0] Train Loss: 0.14260394871234894\n",
            "Epoch [8/10] Batch [100] Train Loss: 0.177839994430542\n",
            "Epoch [8/10] Batch [200] Train Loss: 0.26005831360816956\n",
            "Epoch [8/10] Batch [300] Train Loss: 0.1457052081823349\n",
            "Epoch [8/10] Batch [400] Train Loss: 0.17647139728069305\n",
            "Epoch [8/10] Train Loss: 0.0012080997441584866 Train Accuracy: 95.47666666666667\n",
            "Valid Epoch [8/10]\n",
            "Epoch [8/10] Valid Loss: 0.0006813590596662834 Valid Accuracy: 97.59\n",
            "Epoch [8/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n",
            "Train Epoch [9/10]\n",
            "Epoch [9/10] Batch [0] Train Loss: 0.07957115769386292\n",
            "Epoch [9/10] Batch [100] Train Loss: 0.12074045836925507\n",
            "Epoch [9/10] Batch [200] Train Loss: 0.1795433759689331\n",
            "Epoch [9/10] Batch [300] Train Loss: 0.1403198391199112\n",
            "Epoch [9/10] Batch [400] Train Loss: 0.11119394749403\n",
            "Epoch [9/10] Train Loss: 0.0011706567105526726 Train Accuracy: 95.62\n",
            "Valid Epoch [9/10]\n",
            "Epoch [9/10] Valid Loss: 0.0006090921304770746 Valid Accuracy: 97.9\n",
            "Epoch [9/10] Valid Model Saved: checkpoint/alexnet_mnist.pt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}